{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1.) Import an asset price from Yahoo Finance"
      ],
      "metadata": {
        "id": "6dJuZDx9qWeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxUUnTVTrx3m",
        "outputId": "184a82bc-26cd-4cf9-ffb7-4f50439c6cfb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.2.12-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html5lib>=1.1\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.8/dist-packages (from yfinance) (2022.7.1)\n",
            "Collecting beautifulsoup4>=4.11.1\n",
            "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from yfinance) (0.0.11)\n",
            "Collecting cryptography>=3.3.2\n",
            "  Downloading cryptography-39.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.22.4)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.8/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.4.4)\n",
            "Collecting frozendict>=2.3.4\n",
            "  Downloading frozendict-2.3.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.2/111.2 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.26\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.4-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from html5lib>=1.1->yfinance) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (3.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
            "Installing collected packages: soupsieve, requests, html5lib, frozendict, cryptography, beautifulsoup4, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "  Attempting uninstall: html5lib\n",
            "    Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed beautifulsoup4-4.11.2 cryptography-39.0.1 frozendict-2.3.5 html5lib-1.1 requests-2.28.2 soupsieve-2.4 yfinance-0.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3bcwJb4rp93",
        "outputId": "62de4770-b425-49dc-8490-7a8bc22d1e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "\n",
        "########################################\n",
        "####Pick your ticker and time period####\n",
        "########################################\n",
        "stock_data = yf.download(\"AAPL\", start=\"1990-01-01\", end=\"2023-02-24\")\n",
        "\n",
        "\n",
        "# Preprocess data\n",
        "scaled_data = np.array(stock_data[\"Close\"].pct_change().dropna()).reshape(-1,1)\n",
        "\n",
        "\n",
        "# Split data into training and test sets\n",
        "training_data_len = int(len(scaled_data) * 0.8)\n",
        "train_data = scaled_data[0:training_data_len, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.) Create your x_train/y_train data so that your RNN uses percentage change data to make a binary forecast where the stock moves up or down the next day\n",
        "# Build an RNN Architecture accordingly"
      ],
      "metadata": {
        "id": "foHoGy9hq3_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################\n",
        "####Pick your input size and edit to make binary forecast####\n",
        "############################################################# \n",
        "input_size = 5      # number of time lag \n",
        "\n",
        "# # create x_train/y_train\n",
        "# x_train = []\n",
        "# y_train = []\n",
        "\n",
        "# for i in range(input_size, len(train_data)):\n",
        "#     x_train.append(train_data[i-input_size:i, 0])\n",
        "#     y_train.append(np.where(train_data[i] >=0, 1, -1)) # 1 if it went up, 0 if it went down - classification\n",
        "\n",
        "# x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "# x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "# x_train\n",
        "\n",
        "# Define function\n",
        "def make_input(train_data, input_size):\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    for i in range(input_size, len(train_data)):\n",
        "        x_train.append(train_data[i-input_size:i, 0])\n",
        "        y_train.append(np.where(train_data[i] >=0, 1, -1)) # 1 if it went up, 0 if it went down - classification\n",
        "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "    return x_train, y_train\n",
        "\n",
        "x_train, y_train = make_input(train_data, input_size)\n",
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVLk0b3Ip29S",
        "outputId": "c0ca328c-611f-4dfd-a169-10333f5b3b64"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.00671094],\n",
              "        [ 0.00333617],\n",
              "        [ 0.00332206],\n",
              "        [ 0.00662204],\n",
              "        [-0.00986776]],\n",
              "\n",
              "       [[ 0.00333617],\n",
              "        [ 0.00332206],\n",
              "        [ 0.00662204],\n",
              "        [-0.00986776],\n",
              "        [-0.04318949]],\n",
              "\n",
              "       [[ 0.00332206],\n",
              "        [ 0.00662204],\n",
              "        [-0.00986776],\n",
              "        [-0.04318949],\n",
              "        [-0.0416671 ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-0.0280957 ],\n",
              "        [-0.01456103],\n",
              "        [ 0.01684045],\n",
              "        [ 0.00865483],\n",
              "        [ 0.01271183]],\n",
              "\n",
              "       [[-0.01456103],\n",
              "        [ 0.01684045],\n",
              "        [ 0.00865483],\n",
              "        [ 0.01271183],\n",
              "        [ 0.00303348]],\n",
              "\n",
              "       [[ 0.01684045],\n",
              "        [ 0.00865483],\n",
              "        [ 0.01271183],\n",
              "        [ 0.00303348],\n",
              "        [-0.00938577]]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################################\n",
        "####Build Your RNN Architecture####\n",
        "###################################\n",
        "# model (1)\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(x_train.shape[1], return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "# model.add(LSTM(x_train.shape[1], input_shape=(x_train.shape[1], 1)))\n",
        "# model.add(Dense(20, activation='relu'))\n",
        "# model.add(Dense(10, activation='relu'))\n",
        "# model.add(Dense(5, activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid')) # last layer should correspond to classification sigmoid/softmax\n",
        "\n",
        "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# model.fit(x_train, y_train, batch_size=1, epochs=3)\n",
        "\n",
        "# model (2)\n",
        "model = Sequential()\n",
        "model.add(LSTM(x_train.shape[1], input_shape=(x_train.shape[1], 1)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid')) # last layer should correspond to classification sigmoid/softmax\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=3)"
      ],
      "metadata": {
        "id": "5qGFB5HfqcVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08574d86-7c70-481a-80b0-d2d6cf483eba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "6675/6675 [==============================] - 25s 3ms/step - loss: 1.0054\n",
            "Epoch 2/3\n",
            "6675/6675 [==============================] - 24s 4ms/step - loss: 0.9992\n",
            "Epoch 3/3\n",
            "6675/6675 [==============================] - 25s 4ms/step - loss: 0.9981\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7fa0767400>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the predictions\n",
        "predictions_in = model.predict(x_train)\n",
        "print(predictions_in)\n",
        "\n",
        "# Find the best threshold (criteria: accuracy)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "threshold = []\n",
        "accuracy = []\n",
        "\n",
        "for th in np.arange(0.02, 0.09, 0.0001):\n",
        "    y_pred_in = np.where(predictions_in > th, 1, 0)\n",
        "    threshold.append(th)\n",
        "    accuracy.append(accuracy_score(y_train, y_pred_in))\n",
        "\n",
        "threshold_f = pd.DataFrame(list(zip(accuracy)), index=threshold).idxmax()[0]\n",
        "print('threshold: ', threshold_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LwUl9g25tJA",
        "outputId": "1a01bd60-9d23-4e11-be25-c02d93ec6074"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209/209 [==============================] - 1s 2ms/step\n",
            "[[0.03061132]\n",
            " [0.03107343]\n",
            " [0.03130232]\n",
            " ...\n",
            " [0.03042584]\n",
            " [0.03041265]\n",
            " [0.0305466 ]]\n",
            "threshold:  0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.) Test your model and compare insample Accurracy, insample random walk assumption Accuracy, Out of sample Accuracy and out of sample random walk assumption Accuracy using a bar chart"
      ],
      "metadata": {
        "id": "yFhO9vMjsWPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model to the test data\n",
        "test_data = scaled_data[training_data_len - input_size:, :]\n",
        "x_test, y_test = make_input(test_data, input_size)\n",
        "\n",
        "# make predictions\n",
        "predictions_in = model.predict(x_train)  # probability\n",
        "y_pred_in = np.where(predictions_in > threshold_f, 1, 0)\n",
        "predictions_out = model.predict(x_test)  # probability\n",
        "y_pred = np.where(predictions_out > threshold_f, 1, 0)\n",
        "\n",
        "# random walk predictions (random walk assumes the price change to be 0, which is classified as 1 in our model)\n",
        "y_rw_in = np.ones(len(y_pred_in))\n",
        "y_rw = np.ones(len(y_pred))\n",
        "\n",
        "# accuracy scores\n",
        "acc_in = accuracy_score(y_train, y_pred_in)\n",
        "acc_in_rw = accuracy_score(y_train, y_rw_in)\n",
        "acc_out = accuracy_score(y_test, y_pred)\n",
        "acc_out_rw = accuracy_score(y_test, y_rw)"
      ],
      "metadata": {
        "id": "r1Xj6Ji-rwnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc5b228-4920-4690-e940-a3ada36c10dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209/209 [==============================] - 0s 2ms/step\n",
            "53/53 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.array(['In sample', 'In sample r.w', 'out-of-sample', 'out-of-sample r.w'])\n",
        "y = np.array([acc_in, acc_in_rw, acc_out, acc_out_rw])\n",
        "\n",
        "### Plot\n",
        "# Defining the plot size\n",
        "plt.figure(figsize=(8, 4))\n",
        " \n",
        "# Defining the values for x-axis, y-axis\n",
        "# and from which dataframe the values are to be picked\n",
        "plots = sns.barplot(x, y)\n",
        " \n",
        "# Iterating over the bars one-by-one\n",
        "for bar in plots.patches:\n",
        "   \n",
        "  # Using Matplotlib's annotate function and\n",
        "  # passing the coordinates where the annotation shall be done\n",
        "  # x-coordinate: bar.get_x() + bar.get_width() / 2\n",
        "  # y-coordinate: bar.get_height()\n",
        "  # free space to be left to make graph pleasing: (0, 8)\n",
        "  # ha and va stand for the horizontal and vertical alignment\n",
        "  plots.annotate(format(bar.get_height(), '.4f'),\n",
        "                   (bar.get_x() + bar.get_width() / 2,\n",
        "                    bar.get_height()), ha='center', va='center',\n",
        "                   size=10, xytext=(0, 8),\n",
        "                   textcoords='offset points')\n",
        " \n",
        "# Setting the label for y-axis\n",
        "plt.ylabel(\"Accuracy\", size=10)\n",
        "plt.ylim(0,0.6)\n",
        " \n",
        "# Setting the title for the graph\n",
        "plt.title(\"Accuracy scores compared to random walk predictions\", size=15)\n",
        " \n",
        "# Finally showing the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "gJseJ7s15g-q",
        "outputId": "23a49ea5-292a-4e2b-ee03-c4f1a5c2017a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.) Plot in and out of sample accuracy - DON'T DO IT"
      ],
      "metadata": {
        "id": "8bncNwh8tKiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on full dataset\n",
        "\n",
        "test_predict = model.predict(x_test)\n",
        "test_predictions = (test_predict+1).reshape(1,-1) * np.cumprod(y_test+1)\n",
        "\n",
        "train_predict = model.predict(x_train)\n",
        "train_predictions = (train_predict+1).reshape(1,-1) * np.cumprod(y_train+1)\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(stock_data[:training_data_len- input_size].index, np.cumprod(y_train+1), label=\"Training Data\")\n",
        "plt.plot(stock_data[:training_data_len- input_size].index, train_predictions[0], label=\"Training Predictions\")\n",
        "end_val = np.cumprod(y_train+1)[-1]\n",
        "test_predict = model.predict(x_test)\n",
        "test_predictions = (test_predict+1).reshape(1,-1) * (np.cumprod((y_test+1))*end_val)\n",
        "plt.plot(stock_data[training_data_len+1:].index, np.cumprod((y_test+1))*end_val,label=\"Test Data\")\n",
        "plt.plot(stock_data[training_data_len+1:].index, test_predictions[0], label=\"Test Predictions\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Stock Price\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d698mdExtfHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.) Write an observation/conclusion about the graphs from Q4 and Q3"
      ],
      "metadata": {
        "id": "bK_jyyEEtTUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The LSTM model performed poorly and had the same accuracy scores as the random walk predictions. "
      ],
      "metadata": {
        "id": "I8S4Fqjb7YVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.) Create a parameter for number of lags in your input layer. Do a 3-fold CV to test three different time lags. i.e. Tested using 5,10,20 days of previous price data to forecast"
      ],
      "metadata": {
        "id": "pFtrp-lmtw6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "# Define the Keras model\n",
        "###Edit here to create your optimizer \n",
        "def create_model(input_size=input_size):\n",
        "    x_train, y_train = make_input(train_data, input_size)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(x_train.shape[1], input_shape=(x_train.shape[1], 1)))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(5, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid')) # last layer should correspond to classification sigmoid/softmax\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # model.summary()\n",
        "    return model\n",
        "\n",
        "# Wrap the Keras model in a scikit-learn compatible estimator\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Define the hyperparameters to search over\n",
        "# input_size = [5,10,20]\n",
        "# optimizers = ['rmsprop', 'adam', 'Adamax', 'sgd']\n",
        "# param_grid = dict(optimizer=optimizers)\n",
        "# param_grid = dict(input_size=input_size, optimizer=optimizers)\n",
        "param_grid={'input_size':[5,10,20]}\n",
        "\n",
        "# Perform the grid search over the hyperparameters\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(x_train, y_train) \n",
        "\n",
        "# Print the results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11cYy6ADK5Tj",
        "outputId": "71ef7ba2-2b93-4534-ab36-954676caf539"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.523595 using {'input_size': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "##### TEST - OTHER HYPERPARAMETER\n",
        "################################################\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "# Define the Keras model\n",
        "###Edit here to create your optimizer \n",
        "def create_model(optimizer='adam'):\n",
        "    x_train, y_train = make_input(train_data, 5)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(x_train.shape[1], input_shape=(x_train.shape[1], 1)))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(5, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid')) # last layer should correspond to classification sigmoid/softmax\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    # model.summary()\n",
        "    return model\n",
        "\n",
        "# Wrap the Keras model in a scikit-learn compatible estimator\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Define the hyperparameters to search over\n",
        "# input_size = [5,10,20]\n",
        "optimizers = ['rmsprop', 'adam', 'Adamax', 'sgd']\n",
        "param_grid = dict(optimizer=optimizers)\n",
        "# param_grid = dict(input_size=input_size)\n",
        "# param_grid={'input_size':[5,10,20]}\n",
        "\n",
        "# Perform the grid search over the hyperparameters\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(x_train, y_train)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS92cRuWbrEr",
        "outputId": "f804f5e1-cdb9-414e-873e-e3b4b0510b73"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.523595 using {'optimizer': 'rmsprop'}\n"
          ]
        }
      ]
    }
  ]
}